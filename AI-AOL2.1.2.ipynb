{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your CSV file\n",
    "file_path = 'final_dataset.xlsx'\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Get unique classes\n",
    "unique_classes = data['labels'].unique()\n",
    "print(\"Kelas yang terdapat dalam data:\", unique_classes)\n",
    "\n",
    "# Prepare the label encoding\n",
    "data['label_encoded'] = data['labels'].astype('category').cat.codes\n",
    "\n",
    "# Create a mapping of encoded values to labels\n",
    "label_mapping = {label: code for label, code in zip(data['labels'].astype('category').cat.categories, range(len(unique_classes)))}\n",
    "print(\"Mapping label ke encoded value:\", label_mapping)\n",
    "\n",
    "# Split the data (80% train, 10% val, 10% test)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, stratify=temp_data['label_encoded'], random_state=42)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset untuk DataLoader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model_name = BertForSequenceClassification\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>RoBERTa Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "model_name = RobertaForSequenceClassification\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ALBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n",
    "\n",
    "model_name = AlbertForSequenceClassification\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
    "\n",
    "model_name = ElectraForSequenceClassification\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator', num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DeBERTa Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
    "\n",
    "model_name = DebertaForSequenceClassification\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "model = DebertaForSequenceClassification.from_pretrained('microsoft/deberta-base', num_labels=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi model dan tokenizer\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
    "\n",
    "model_name = DebertaForSequenceClassification\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base')\n",
    "model = DebertaForSequenceClassification.from_pretrained('microsoft/deberta-base', num_labels=6)\n",
    "\n",
    "# Tokenisasi data\n",
    "train_encodings = tokenizer(list(train_data['data']), truncation=True, padding=True, max_length=64)\n",
    "val_encodings = tokenizer(list(val_data['data']), truncation=True, padding=True, max_length=64)\n",
    "test_encodings = tokenizer(list(test_data['data']), truncation=True, padding=True, max_length=64)\n",
    "\n",
    "# Membuat DataLoader\n",
    "train_dataset = TextDataset(train_encodings, train_data['label_encoded'].tolist())\n",
    "val_dataset = TextDataset(val_encodings, val_data['label_encoded'].tolist())\n",
    "test_dataset = TextDataset(test_encodings, test_data['label_encoded'].tolist())\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, device):\n",
    "    model.train()\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(10):  # Number of epochs\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        all_train_true_labels = []\n",
    "        all_train_predictions = []\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            all_train_true_labels.extend(labels.cpu().numpy())\n",
    "            all_train_predictions.extend(preds.cpu().numpy())\n",
    "            \n",
    "            if batch_idx % 10 == 0:  # Display every 10 batches\n",
    "                print(f\"Epoch [{epoch + 1}/10], Batch [{batch_idx}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        # Calculate training accuracy for the epoch\n",
    "        train_accuracy = correct_predictions / total_predictions\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        print(f\"\\nEpoch [{epoch + 1}/10] - Training Accuracy: {train_accuracy:.4f}\")\n",
    "        \n",
    "        # Validation accuracy (simplified)\n",
    "        model.eval()\n",
    "        val_correct_predictions = 0\n",
    "        val_total_predictions = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "                val_correct_predictions += (preds == labels).sum().item()\n",
    "                val_total_predictions += labels.size(0)\n",
    "        \n",
    "        val_accuracy = val_correct_predictions / val_total_predictions\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        print(f\"Epoch [{epoch + 1}/10] - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        model.train()  # Switch back to training mode\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), \"DeBERTa.pth\")\n",
    "    print(\"Model has been saved to 'trained_model.pth'\")\n",
    "\n",
    "    # Plotting training and validation accuracies\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    plt.plot(range(1, 11), train_accuracies, label='Train Accuracy', marker='o')\n",
    "    plt.plot(range(1, 11), val_accuracies, label='Validation Accuracy', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy Comparison')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Final Confusion Matrix and Classification Report for Training Data\n",
    "    print(\"\\nFinal Confusion Matrix (Training):\")\n",
    "    label_names = ['Religion', 'business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "    cm_train = confusion_matrix(all_train_true_labels, all_train_predictions)\n",
    "    sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('DeBERTa Confusion Matrix (Training)')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nFinal Classification Report (Training):\")\n",
    "    print(classification_report(all_train_true_labels, all_train_predictions, target_names=label_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set after training\n",
    "def evaluate_test(model, test_loader, device):\n",
    "    # Load state dict dari file yang telah disimpan\n",
    "    model.load_state_dict(torch.load(\"DeBERTa.pth\"))\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            if batch_idx % 10 == 0:  # Display every 10 batches\n",
    "                print(f\"Evaluating Batch [{batch_idx}]...\")\n",
    "\n",
    "    # Calculate test metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Confusion matrix for test set\n",
    "    cm_test = confusion_matrix(true_labels, predictions)\n",
    "    label_names = ['Religion', 'business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix DeBERTa Model')\n",
    "    plt.show()     \n",
    "\n",
    "    # Print the classification report for test set\n",
    "    print(\"\\nClassification Report (Test):\")\n",
    "    print(classification_report(true_labels, predictions, target_names=label_names))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menjalankan model di GPU atau CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Run the training and evaluation process\n",
    "train(model, train_loader, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, evaluate on the test set\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.cuda.empty_cache()\n",
    "evaluate_test(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
